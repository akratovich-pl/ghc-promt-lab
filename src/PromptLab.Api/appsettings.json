{
  "Serilog": {
    "Using": ["Serilog.Sinks.Console", "Serilog.Sinks.File"],
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "Microsoft.AspNetCore": "Warning",
        "Microsoft.EntityFrameworkCore": "Warning",
        "System": "Warning"
      }
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "outputTemplate": "[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj} {Properties:j}{NewLine}{Exception}"
        }
      },
      {
        "Name": "File",
        "Args": {
          "path": "logs/promptlab-.log",
          "rollingInterval": "Day",
          "retainedFileCountLimit": 30,
          "outputTemplate": "{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] {Message:lj} {Properties:j}{NewLine}{Exception}",
          "shared": true
        }
      }
    ],
    "Enrich": ["FromLogContext", "WithMachineName", "WithThreadId"],
    "Properties": {
      "Application": "PromptLab.Api"
    }
  },
  "AllowedHosts": "*",
  "ConnectionStrings": {
    "DefaultConnection": "Data Source=promptlab.db"
  },
  "Cors": {
    "AllowedOrigins": [
      "http://localhost:5173",
      "http://localhost:5251",
      "https://localhost:7251"
    ]
  },
  "Providers": {
    "Google": {
      "Name": "Google",
      "BaseUrl": "https://generativelanguage.googleapis.com",
      "ApiVersion": "v1beta",
      "MaxRetries": 3,
      "TimeoutSeconds": 30,
      "DefaultModel": "gemini-1.5-flash",
      "Models": [
        {
          "Name": "gemini-1.5-flash",
          "DisplayName": "Gemini 1.5 Flash",
          "MaxTokens": 8192,
          "InputCostPer1kTokens": 0.00007,
          "OutputCostPer1kTokens": 0.0003
        },
        {
          "Name": "gemini-1.5-pro",
          "DisplayName": "Gemini 1.5 Pro",
          "MaxTokens": 8192,
          "InputCostPer1kTokens": 0.00125,
          "OutputCostPer1kTokens": 0.005
        }
      ]
    },
    "Groq": {
      "Name": "Groq",
      "BaseUrl": "https://api.groq.com/openai",
      "ApiVersion": "v1",
      "MaxRetries": 3,
      "TimeoutSeconds": 30,
      "DefaultModel": "llama-3.3-70b-versatile",
      "Models": [
        {
          "Name": "llama-3.3-70b-versatile",
          "DisplayName": "Llama 3.3 70B Versatile",
          "MaxTokens": 8000,
          "InputCostPer1kTokens": 0.00059,
          "OutputCostPer1kTokens": 0.00079
        },
        {
          "Name": "llama-3.1-70b-versatile",
          "DisplayName": "Llama 3.1 70B Versatile",
          "MaxTokens": 8000,
          "InputCostPer1kTokens": 0.00059,
          "OutputCostPer1kTokens": 0.00079
        },
        {
          "Name": "llama3-70b-8192",
          "DisplayName": "Llama 3 70B",
          "MaxTokens": 8192,
          "InputCostPer1kTokens": 0.00059,
          "OutputCostPer1kTokens": 0.00079
        },
        {
          "Name": "llama3-8b-8192",
          "DisplayName": "Llama 3 8B",
          "MaxTokens": 8192,
          "InputCostPer1kTokens": 0.00005,
          "OutputCostPer1kTokens": 0.00008
        }
      ]
    }
  },
  "RateLimiting": {
    "RequestsPerMinute": 60,
    "RequestsPerHour": 1000,
    "Enabled": true
  }
}